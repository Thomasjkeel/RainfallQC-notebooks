{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530f7296-c84f-4910-909d-b2c1f99fc035",
   "metadata": {},
   "source": [
    "# Neighbour checks for quality control flags\n",
    "Covers QC16-25\n",
    "\n",
    "## Table of contents\n",
    "[Utility neighbour functions](#utility-neighbour-functions)  \n",
    "[QC16 Daily neighbours (wet)](#QC16---Daily-neighbours-wet)  \n",
    "[QC17 Hourly neighbours (wet)](#QC17---Hourly-neighbours-wet)  \n",
    "[QC18 Daily neighbours (dry)](#QC18---Daily-neighbours-dry)  \n",
    "[QC19 Hourly neighbours (dry)](#QC19---Hourly-neighbours-dry)  \n",
    "[QC20 Monthly neighbours](#QC20---Monthly-neighbours)  \n",
    "[QC21 Timing offset](#QC21---Timing-offset)  \n",
    "[QC22 Pre-QC Affinity](#QC22---Pre-QC-Affinity)  \n",
    "[QC23 Pre-QC Pearson](#QC23---Pre-QC-Pearson)  \n",
    "[QC24 Daily factor](#QC24---Daily-factor)  \n",
    "[QC25 Monthly factor](#QC25---Monthly-factor)  \n",
    "\n",
    "See '3.3.4 Neighbouring gauge checks on large values' in Lewis et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4b1a0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "\n",
    "import zipfile ## used once for Intense format data\n",
    "import pandas as pd ## used once for Intense format data\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01b6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_STATION_ID = \"DE_02483\"\n",
    "DISTANCE_THRESHOLD = 50 # 50 km\n",
    "OVERLAP_THRESHOLD = 365*3 # three years\n",
    "\n",
    "## Data reading globals\n",
    "GAUGE_DATA_PATH = \"../data/gauge_data\"\n",
    "DATA_ROWS_TO_SKIP = 20 ## First 20 rows are metadata TODO: what if not?\n",
    "UNIT_COL = \"new_units\" ## There is an original_units col too TODO: think of way to do this for different data\n",
    "\n",
    "MULTIPLYING_FACTORS = {\"hourly\": 24, \"daily\": 1} ## compared to daily reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0436c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(data_path):\n",
    "    metadata = {}\n",
    "\n",
    "    with open(data_path, 'r') as f:\n",
    "        while True:\n",
    "            key, val = f.readline().strip().split(':', maxsplit=1)\n",
    "            key = key.lower().replace(' ', '_')\n",
    "            metadata[key.strip()] = val.strip()\n",
    "            if key == 'other':\n",
    "                break\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72451179",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_metadata = read_metadata(data_path='../data/gauge_data/DE_02483.txt')\n",
    "station_metadata['start_datetime'] = datetime.datetime.strptime(station_metadata['start_datetime'], '%Y%m%d%H')\n",
    "station_metadata['end_datetime'] = datetime.datetime.strptime(station_metadata['end_datetime'], '%Y%m%d%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc198b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_to_gauge_data(station_metadata, gauge_data, time_multiplying_factor):\n",
    "    \"\"\"\n",
    "    Add datetime column to gauge data using metadata from that gauge.\n",
    "    NOTE: Could maybe extend so can find metadata if not provided?\n",
    "    \"\"\"\n",
    "    startdate = station_metadata['start_datetime']\n",
    "    enddate = station_metadata['end_datetime']\n",
    "    assert isinstance(startdate, datetime.datetime), \"Please convert start_ and end_datetime to datetime.datetime objects\"\n",
    "\n",
    "    date_interval = []\n",
    "    delta_days = (enddate+datetime.timedelta(days=1) - startdate).days\n",
    "    for i in range(delta_days * time_multiplying_factor):\n",
    "        date_interval.append(startdate + datetime.timedelta(hours=i))\n",
    "\n",
    "    ## add datetime column\n",
    "    assert len(gauge_data) == len(date_interval)\n",
    "    gauge_data = gauge_data.with_columns(time=pl.Series(date_interval)) ## set time columns\n",
    "\n",
    "    return gauge_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783e5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_col = f'rain_{station_metadata['original_units']}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba66818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in gauge data\n",
    "target_gauge = pl.read_csv('../data/gauge_data/DE_02483.txt', skip_rows=20, schema_overrides={rain_col: pl.Float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4d06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gauge = add_datetime_to_gauge_data(station_metadata, target_gauge, time_multiplying_factor=MULTIPLYING_FACTORS['hourly'])\n",
    "target_gauge = target_gauge.select(['time', rain_col]) ## Reorder (to look nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f6f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make no data vals nans\n",
    "target_gauge = target_gauge.with_columns(pl.when(pl.col(rain_col) == int(station_metadata['no_data_value'])).then(np.nan).otherwise(pl.col(rain_col)).alias(rain_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57da3cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 00:00:00</td><td>0.9</td></tr><tr><td>2006-01-01 01:00:00</td><td>0.3</td></tr><tr><td>2006-01-01 02:00:00</td><td>0.3</td></tr><tr><td>2006-01-01 03:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 04:00:00</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2006-01-01 00:00:00 ┆ 0.9     │\n",
       "│ 2006-01-01 01:00:00 ┆ 0.3     │\n",
       "│ 2006-01-01 02:00:00 ┆ 0.3     │\n",
       "│ 2006-01-01 03:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 04:00:00 ┆ 0.0     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_gauge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e34f32",
   "metadata": {},
   "source": [
    "# Utility neighbour functions\n",
    "TODO: convert to Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05d71b",
   "metadata": {},
   "source": [
    "### Part 1. Make or read summary metadata of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56dd5d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/gauge_data/DE_02483.txt',\n",
       " '../data/gauge_data/DE_00310.txt',\n",
       " '../data/gauge_data/DE_00389.txt',\n",
       " '../data/gauge_data/DE_00390.txt',\n",
       " '../data/gauge_data/DE_01300.txt',\n",
       " '../data/gauge_data/DE_02718.txt',\n",
       " '../data/gauge_data/DE_03215.txt',\n",
       " '../data/gauge_data/DE_04313.txt',\n",
       " '../data/gauge_data/DE_04488.txt',\n",
       " '../data/gauge_data/DE_06264.txt',\n",
       " '../data/gauge_data/DE_06303.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Could work by checking if metadata already exists (or user can input)\n",
    "all_gauge_data_paths = glob.glob(f\"{GAUGE_DATA_PATH}/*.txt\")\n",
    "all_gauge_data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b217948",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_station_metadata_list = []\n",
    "for ind, file in enumerate(all_gauge_data_paths):\n",
    "    one_station_metadata = read_metadata(data_path=file)\n",
    "    all_station_metadata_list.append(one_station_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442c16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>station_id</th><th>country</th><th>original_station_number</th><th>original_station_name</th><th>path_to_original_data</th><th>latitude</th><th>longitude</th><th>start_datetime</th><th>end_datetime</th><th>elevation</th><th>number_of_records</th><th>percent_missing_data</th><th>original_timestep</th><th>new_timestep</th><th>original_units</th><th>new_units</th><th>time_zone</th><th>daylight_saving_info</th><th>no_data_value</th><th>resolution</th><th>other</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>datetime[μs]</td><td>datetime[μs]</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;DE_02483&quot;</td><td>&quot;Germany&quot;</td><td>&quot;02483&quot;</td><td>&quot;NA&quot;</td><td>&quot;B:/INTENSE data/Original data/…</td><td>51.1803</td><td>8.4891</td><td>2006-01-01 00:00:00</td><td>2010-12-31 23:00:00</td><td>&quot;839m&quot;</td><td>&quot;43824&quot;</td><td>&quot;0.00&quot;</td><td>&quot;1hr&quot;</td><td>&quot;1hr&quot;</td><td>&quot;mm&quot;</td><td>&quot;mm&quot;</td><td>&quot;CET&quot;</td><td>&quot;NA&quot;</td><td>&quot;-999&quot;</td><td>&quot;0.10&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;DE_00310&quot;</td><td>&quot;Germany&quot;</td><td>&quot;00310&quot;</td><td>&quot;NA&quot;</td><td>&quot;B:/INTENSE data/Original data/…</td><td>51.0662</td><td>8.5373</td><td>2006-01-01 00:00:00</td><td>2010-12-31 23:00:00</td><td>&quot;590m&quot;</td><td>&quot;43824&quot;</td><td>&quot;0.00&quot;</td><td>&quot;1hr&quot;</td><td>&quot;1hr&quot;</td><td>&quot;mm&quot;</td><td>&quot;mm&quot;</td><td>&quot;CET&quot;</td><td>&quot;NA&quot;</td><td>&quot;-999&quot;</td><td>&quot;0.10&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;DE_00389&quot;</td><td>&quot;Germany&quot;</td><td>&quot;00389&quot;</td><td>&quot;NA&quot;</td><td>&quot;B:/INTENSE data/Original data/…</td><td>51.0148</td><td>8.4318</td><td>2009-11-01 00:00:00</td><td>2010-12-31 23:00:00</td><td>&quot;436m&quot;</td><td>&quot;10224&quot;</td><td>&quot;0.00&quot;</td><td>&quot;1hr&quot;</td><td>&quot;1hr&quot;</td><td>&quot;mm&quot;</td><td>&quot;mm&quot;</td><td>&quot;CET&quot;</td><td>&quot;NA&quot;</td><td>&quot;-999&quot;</td><td>&quot;0.10&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;DE_00390&quot;</td><td>&quot;Germany&quot;</td><td>&quot;00390&quot;</td><td>&quot;NA&quot;</td><td>&quot;B:/INTENSE data/Original data/…</td><td>50.9837</td><td>8.3679</td><td>2006-01-01 00:00:00</td><td>2010-12-31 23:00:00</td><td>&quot;610m&quot;</td><td>&quot;43824&quot;</td><td>&quot;0.00&quot;</td><td>&quot;1hr&quot;</td><td>&quot;1hr&quot;</td><td>&quot;mm&quot;</td><td>&quot;mm&quot;</td><td>&quot;CET&quot;</td><td>&quot;NA&quot;</td><td>&quot;-999&quot;</td><td>&quot;0.10&quot;</td><td>&quot;&quot;</td></tr><tr><td>&quot;DE_01300&quot;</td><td>&quot;Germany&quot;</td><td>&quot;01300&quot;</td><td>&quot;NA&quot;</td><td>&quot;B:/INTENSE data/Original data/…</td><td>51.254</td><td>8.1565</td><td>2006-01-01 00:00:00</td><td>2010-12-31 23:00:00</td><td>&quot;351m&quot;</td><td>&quot;43824&quot;</td><td>&quot;0.00&quot;</td><td>&quot;1hr&quot;</td><td>&quot;1hr&quot;</td><td>&quot;mm&quot;</td><td>&quot;mm&quot;</td><td>&quot;CET&quot;</td><td>&quot;NA&quot;</td><td>&quot;-999&quot;</td><td>&quot;0.10&quot;</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌────────────┬─────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬───────┐\n",
       "│ station_id ┆ country ┆ original_s ┆ original_s ┆ … ┆ daylight_s ┆ no_data_va ┆ resolutio ┆ other │\n",
       "│ ---        ┆ ---     ┆ tation_num ┆ tation_nam ┆   ┆ aving_info ┆ lue        ┆ n         ┆ ---   │\n",
       "│ str        ┆ str     ┆ ber        ┆ e          ┆   ┆ ---        ┆ ---        ┆ ---       ┆ str   │\n",
       "│            ┆         ┆ ---        ┆ ---        ┆   ┆ str        ┆ str        ┆ str       ┆       │\n",
       "│            ┆         ┆ str        ┆ str        ┆   ┆            ┆            ┆           ┆       │\n",
       "╞════════════╪═════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════╡\n",
       "│ DE_02483   ┆ Germany ┆ 02483      ┆ NA         ┆ … ┆ NA         ┆ -999       ┆ 0.10      ┆       │\n",
       "│ DE_00310   ┆ Germany ┆ 00310      ┆ NA         ┆ … ┆ NA         ┆ -999       ┆ 0.10      ┆       │\n",
       "│ DE_00389   ┆ Germany ┆ 00389      ┆ NA         ┆ … ┆ NA         ┆ -999       ┆ 0.10      ┆       │\n",
       "│ DE_00390   ┆ Germany ┆ 00390      ┆ NA         ┆ … ┆ NA         ┆ -999       ┆ 0.10      ┆       │\n",
       "│ DE_01300   ┆ Germany ┆ 01300      ┆ NA         ┆ … ┆ NA         ┆ -999       ┆ 0.10      ┆       │\n",
       "└────────────┴─────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_station_metadata = pl.from_dicts(all_station_metadata_list)\n",
    "all_station_metadata = all_station_metadata.with_columns(\n",
    "    pl.col(\"latitude\").cast(pl.Float64),\n",
    "    pl.col(\"longitude\").cast(pl.Float64),\n",
    "    (pl.col(\"start_datetime\")+'00').str.strptime(pl.Datetime, \"%Y%m%d%H%M\"),\n",
    "    (pl.col(\"end_datetime\")+'00').str.strptime(pl.Datetime, \"%Y%m%d%H%M\"),\n",
    ")\n",
    "all_station_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12847bb",
   "metadata": {},
   "source": [
    "### Part 2. Compute distance from target station\n",
    "TODO: What if the location data is in a different projection i.e. EPSG: 27700?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_from_target_id(metadata, target_id):\n",
    "    target_station = metadata.filter(pl.col(\"station_id\") == target_id)\n",
    "    target_latlon = (target_station['latitude'].item(), target_station['longitude'].item())\n",
    "\n",
    "    neighbour_distances = {}\n",
    "    for other_station_id, other_lat, other_lon in metadata[['station_id', 'latitude', 'longitude']].rows():\n",
    "\n",
    "        neighbour_distances[other_station_id] = geopy.distance.geodesic(target_latlon, (other_lat, other_lon)).kilometers\n",
    "    return neighbour_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5e59fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DE_02483': 0.0,\n",
       " 'DE_00310': 13.134594190689885,\n",
       " 'DE_00389': 18.844342416100808,\n",
       " 'DE_00390': 23.462778369145934,\n",
       " 'DE_01300': 24.64263807685722,\n",
       " 'DE_02718': 24.361752991036987,\n",
       " 'DE_03215': 15.710073576478786,\n",
       " 'DE_04313': 35.397225659812456,\n",
       " 'DE_04488': 15.929311137997068,\n",
       " 'DE_06264': 28.343769567230837,\n",
       " 'DE_06303': 13.96385857171046}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours_distances = compute_distance_from_target_id(all_station_metadata, TARGET_STATION_ID)\n",
    "neighbours_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a05ce598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE: do we want to avoid using geopy.distance and simply write a distance function?\n",
    "# # ALTERNATIVE: maybe precomupte a matrix of distances?\n",
    "# all_station_dist_mtx = scipy.spatial.distance.cdist(all_station_metadata[['latitude', 'longitude']].rows(),\n",
    "#                                         all_station_metadata[['latitude', 'longitude']].rows(),\n",
    "#                                         metric=lambda pnt1, pnt2: geopy.distance.geodesic(pnt1, pnt2).kilometers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d4dc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>station_id</th><th>distances</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;DE_02483&quot;</td><td>0.0</td></tr><tr><td>&quot;DE_00310&quot;</td><td>13.134594</td></tr><tr><td>&quot;DE_00389&quot;</td><td>18.844342</td></tr><tr><td>&quot;DE_00390&quot;</td><td>23.462778</td></tr><tr><td>&quot;DE_01300&quot;</td><td>24.642638</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;DE_03215&quot;</td><td>15.710074</td></tr><tr><td>&quot;DE_04313&quot;</td><td>35.397226</td></tr><tr><td>&quot;DE_04488&quot;</td><td>15.929311</td></tr><tr><td>&quot;DE_06264&quot;</td><td>28.34377</td></tr><tr><td>&quot;DE_06303&quot;</td><td>13.963859</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ station_id ┆ distances │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ DE_02483   ┆ 0.0       │\n",
       "│ DE_00310   ┆ 13.134594 │\n",
       "│ DE_00389   ┆ 18.844342 │\n",
       "│ DE_00390   ┆ 23.462778 │\n",
       "│ DE_01300   ┆ 24.642638 │\n",
       "│ …          ┆ …         │\n",
       "│ DE_03215   ┆ 15.710074 │\n",
       "│ DE_04313   ┆ 35.397226 │\n",
       "│ DE_04488   ┆ 15.929311 │\n",
       "│ DE_06264   ┆ 28.34377  │\n",
       "│ DE_06303   ┆ 13.963859 │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours_distances_df = pl.DataFrame({\"station_id\": neighbours_distances.keys(),\n",
    "              \"distances\": neighbours_distances.values()\n",
    "              })\n",
    "neighbours_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a1e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>station_id</th><th>distances</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;DE_00310&quot;</td><td>13.134594</td></tr><tr><td>&quot;DE_06303&quot;</td><td>13.963859</td></tr><tr><td>&quot;DE_03215&quot;</td><td>15.710074</td></tr><tr><td>&quot;DE_04488&quot;</td><td>15.929311</td></tr><tr><td>&quot;DE_00389&quot;</td><td>18.844342</td></tr><tr><td>&quot;DE_00390&quot;</td><td>23.462778</td></tr><tr><td>&quot;DE_02718&quot;</td><td>24.361753</td></tr><tr><td>&quot;DE_01300&quot;</td><td>24.642638</td></tr><tr><td>&quot;DE_06264&quot;</td><td>28.34377</td></tr><tr><td>&quot;DE_04313&quot;</td><td>35.397226</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ station_id ┆ distances │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ DE_00310   ┆ 13.134594 │\n",
       "│ DE_06303   ┆ 13.963859 │\n",
       "│ DE_03215   ┆ 15.710074 │\n",
       "│ DE_04488   ┆ 15.929311 │\n",
       "│ DE_00389   ┆ 18.844342 │\n",
       "│ DE_00390   ┆ 23.462778 │\n",
       "│ DE_02718   ┆ 24.361753 │\n",
       "│ DE_01300   ┆ 24.642638 │\n",
       "│ DE_06264   ┆ 28.34377  │\n",
       "│ DE_04313   ┆ 35.397226 │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Subset based on 50 km\n",
    "close_neighbours = neighbours_distances_df.filter(\n",
    "    (pl.col(\"distances\") <= DISTANCE_THRESHOLD) &\n",
    "    (pl.col(\"distances\") != 0)\n",
    "    )\n",
    "\n",
    "## closest 10 \n",
    "close_neighbours.sort('distances')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635d967",
   "metadata": {},
   "source": [
    "### Part 3. Compute the temporal overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ceaafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_days(start_1, end_1, start_2, end_2):\n",
    "    ## TODO: add cast to datetime functionality/checks\n",
    "    ## compute overlap\n",
    "    overlap_start = max(start_1, start_2)\n",
    "    overlap_end = min(end_1, end_2)\n",
    "\n",
    "    overlap_days = max(0, (overlap_end - overlap_start).days)\n",
    "\n",
    "    return overlap_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9996026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_days_from_target_id(metadata, target_id):\n",
    "    target_station = metadata.filter(pl.col(\"station_id\") == target_id)\n",
    "    start_1, end_1 = target_station['start_datetime'].item(), target_station['end_datetime'].item()\n",
    "\n",
    "    neighbour_overlap_days = {}\n",
    "    for other_station_id, start_2, end_2 in metadata[['station_id', 'start_datetime', 'end_datetime']].rows():\n",
    "        if target_id == other_station_id:\n",
    "            continue\n",
    "\n",
    "        neighbour_overlap_days[other_station_id] = compute_overlap_days(start_1, end_1, start_2, end_2)\n",
    "    return neighbour_overlap_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d7cb147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DE_00310': 1825,\n",
       " 'DE_00389': 425,\n",
       " 'DE_00390': 1825,\n",
       " 'DE_01300': 1825,\n",
       " 'DE_02718': 1825,\n",
       " 'DE_03215': 1309,\n",
       " 'DE_04313': 1825,\n",
       " 'DE_04488': 1613,\n",
       " 'DE_06264': 1825,\n",
       " 'DE_06303': 1825}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbour_overlap_days = compute_overlap_days_from_target_id(all_station_metadata, TARGET_STATION_ID)\n",
    "neighbour_overlap_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed8d5d",
   "metadata": {},
   "source": [
    "#### Subset based on 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f13c19aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>station_id</th><th>overlap_days</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;DE_00310&quot;</td><td>1825</td></tr><tr><td>&quot;DE_00389&quot;</td><td>425</td></tr><tr><td>&quot;DE_00390&quot;</td><td>1825</td></tr><tr><td>&quot;DE_01300&quot;</td><td>1825</td></tr><tr><td>&quot;DE_02718&quot;</td><td>1825</td></tr><tr><td>&quot;DE_03215&quot;</td><td>1309</td></tr><tr><td>&quot;DE_04313&quot;</td><td>1825</td></tr><tr><td>&quot;DE_04488&quot;</td><td>1613</td></tr><tr><td>&quot;DE_06264&quot;</td><td>1825</td></tr><tr><td>&quot;DE_06303&quot;</td><td>1825</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────┬──────────────┐\n",
       "│ station_id ┆ overlap_days │\n",
       "│ ---        ┆ ---          │\n",
       "│ str        ┆ i64          │\n",
       "╞════════════╪══════════════╡\n",
       "│ DE_00310   ┆ 1825         │\n",
       "│ DE_00389   ┆ 425          │\n",
       "│ DE_00390   ┆ 1825         │\n",
       "│ DE_01300   ┆ 1825         │\n",
       "│ DE_02718   ┆ 1825         │\n",
       "│ DE_03215   ┆ 1309         │\n",
       "│ DE_04313   ┆ 1825         │\n",
       "│ DE_04488   ┆ 1613         │\n",
       "│ DE_06264   ┆ 1825         │\n",
       "│ DE_06303   ┆ 1825         │\n",
       "└────────────┴──────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbour_overlap_days_df = pl.DataFrame({\"station_id\": neighbour_overlap_days.keys(),\n",
    "              \"overlap_days\": neighbour_overlap_days.values()\n",
    "              })\n",
    "neighbour_overlap_days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e506ef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>station_id</th><th>overlap_days</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;DE_00310&quot;</td><td>1825</td></tr><tr><td>&quot;DE_00390&quot;</td><td>1825</td></tr><tr><td>&quot;DE_01300&quot;</td><td>1825</td></tr><tr><td>&quot;DE_02718&quot;</td><td>1825</td></tr><tr><td>&quot;DE_03215&quot;</td><td>1309</td></tr><tr><td>&quot;DE_04313&quot;</td><td>1825</td></tr><tr><td>&quot;DE_04488&quot;</td><td>1613</td></tr><tr><td>&quot;DE_06264&quot;</td><td>1825</td></tr><tr><td>&quot;DE_06303&quot;</td><td>1825</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬──────────────┐\n",
       "│ station_id ┆ overlap_days │\n",
       "│ ---        ┆ ---          │\n",
       "│ str        ┆ i64          │\n",
       "╞════════════╪══════════════╡\n",
       "│ DE_00310   ┆ 1825         │\n",
       "│ DE_00390   ┆ 1825         │\n",
       "│ DE_01300   ┆ 1825         │\n",
       "│ DE_02718   ┆ 1825         │\n",
       "│ DE_03215   ┆ 1309         │\n",
       "│ DE_04313   ┆ 1825         │\n",
       "│ DE_04488   ┆ 1613         │\n",
       "│ DE_06264   ┆ 1825         │\n",
       "│ DE_06303   ┆ 1825         │\n",
       "└────────────┴──────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbour_overlap_days_df.filter(\n",
    "    pl.col(\"overlap_days\") >= OVERLAP_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f159f4d",
   "metadata": {},
   "source": [
    "## Part 4. Bring together to get neighbours both close and overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d2d7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_closest_gauges = 10 ## based on IntenseQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0e7071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset based on 50 km\n",
    "close_neighbour_ids = neighbours_distances_df.filter(\n",
    "    (pl.col(\"distances\") <= DISTANCE_THRESHOLD) &\n",
    "    (pl.col(\"distances\") != 0)\n",
    ")\n",
    "## closest 10 values\n",
    "closest_neighbour_ids = close_neighbour_ids.sort('distances')[:num_closest_gauges]['station_id'].to_list()\n",
    "\n",
    "## Subset based on 3 years\n",
    "overlapping_neighbour_ids = neighbour_overlap_days_df.filter(\n",
    "    pl.col(\"overlap_days\") >= OVERLAP_THRESHOLD\n",
    ")['station_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1517bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DE_00310',\n",
       " 'DE_00390',\n",
       " 'DE_01300',\n",
       " 'DE_02718',\n",
       " 'DE_03215',\n",
       " 'DE_04313',\n",
       " 'DE_04488',\n",
       " 'DE_06264',\n",
       " 'DE_06303'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neighbour_ids = set(overlapping_neighbour_ids).intersection(set(closest_neighbour_ids))\n",
    "all_neighbour_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9482e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neighbour_ids_paths = {}\n",
    "for id in all_neighbour_ids:\n",
    "    ids_path = glob.glob(f\"{GAUGE_DATA_PATH}/*{id}.txt\")\n",
    "    assert len(ids_path) == 1, f\"There are {len(ids_path)} data files for {id}\"\n",
    "    all_neighbour_ids_paths[id] = ids_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07ddf6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DE_06264': '../data/gauge_data/DE_06264.txt',\n",
       " 'DE_01300': '../data/gauge_data/DE_01300.txt',\n",
       " 'DE_06303': '../data/gauge_data/DE_06303.txt',\n",
       " 'DE_02718': '../data/gauge_data/DE_02718.txt',\n",
       " 'DE_04488': '../data/gauge_data/DE_04488.txt',\n",
       " 'DE_00310': '../data/gauge_data/DE_00310.txt',\n",
       " 'DE_03215': '../data/gauge_data/DE_03215.txt',\n",
       " 'DE_00390': '../data/gauge_data/DE_00390.txt',\n",
       " 'DE_04313': '../data/gauge_data/DE_04313.txt'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neighbour_ids_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbabd29",
   "metadata": {},
   "source": [
    "## Part 6. Get neighbouring GDSR gauge by ID (an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "363a4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbour_gauge_data(neighbour_gauge_id, time_multiplying_factor):\n",
    "    data_path = all_neighbour_ids_paths[neighbour_gauge_id]\n",
    "    station_metadata = all_station_metadata.filter(pl.col(\"station_id\") == neighbour_gauge_id)\n",
    "    assert len(station_metadata) == 1, f\"There are {len(station_metadata)} metadata values for {neighbour_gauge_id}. Investigate because there should only be one\"\n",
    "    station_metadata = station_metadata.to_dicts()[0] ## convert df to a dict\n",
    "\n",
    "    ## Read in gauge data\n",
    "    units = station_metadata[UNIT_COL]\n",
    "    rain_col = f'rain_{units}'\n",
    "    gauge_data = pl.read_csv(data_path, skip_rows=DATA_ROWS_TO_SKIP, schema_overrides={rain_col: pl.Float64})\n",
    "\n",
    "    ## make datetime column\n",
    "    gauge_data_w_dates = add_datetime_to_gauge_data(station_metadata, gauge_data, time_multiplying_factor=time_multiplying_factor)\n",
    "    gauge_data_w_dates = gauge_data_w_dates.select(['time', rain_col]) ## Reorder (to look nice)\n",
    "\n",
    "    return gauge_data_w_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46235227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (43_824, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 00:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 01:00:00</td><td>0.1</td></tr><tr><td>2006-01-01 02:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 03:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 04:00:00</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2010-12-31 19:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 20:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 21:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 22:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 23:00:00</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (43_824, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2006-01-01 00:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 01:00:00 ┆ 0.1     │\n",
       "│ 2006-01-01 02:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 03:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 04:00:00 ┆ 0.0     │\n",
       "│ …                   ┆ …       │\n",
       "│ 2010-12-31 19:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 20:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 21:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 22:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 23:00:00 ┆ 0.0     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbour_gauge_data(neighbour_gauge_id='DE_06264', time_multiplying_factor=MULTIPLYING_FACTORS['hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c94c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4feafe1e",
   "metadata": {},
   "source": [
    "## Part 7. Get neighbouring GPCC gauge by ID (an example)\n",
    "\n",
    "#### Note:\n",
    "In the original methodology, GPCC is extracted on the fly\n",
    "\n",
    "Hence, this needs to be refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20fd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f595c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gpcc_daily_paths = {}\n",
    "existing_gpcc_monthly_paths = {}\n",
    "for neighbour_id in all_neighbour_ids_paths.keys():\n",
    "    gpcc_id = neighbour_id.split('DE_')[1].lstrip(\"0\")\n",
    "    existing_gpcc_daily_paths[neighbour_id] = glob.glob(f\"../data/GPCC/tw_{gpcc_id}.zip\")\n",
    "    existing_gpcc_monthly_paths[neighbour_id] = glob.glob(f\"../data/GPCC/mw_{gpcc_id}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3877bc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DE_06264': [],\n",
       " 'DE_01300': [],\n",
       " 'DE_06303': ['../data/GPCC/tw_6303.zip'],\n",
       " 'DE_02718': [],\n",
       " 'DE_04488': [],\n",
       " 'DE_00310': ['../data/GPCC/tw_310.zip'],\n",
       " 'DE_03215': ['../data/GPCC/tw_3215.zip'],\n",
       " 'DE_00390': [],\n",
       " 'DE_04313': []}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_gpcc_daily_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07bd099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_875, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2002-12-01 07:00:00</td><td>3.0</td></tr><tr><td>2002-12-02 07:00:00</td><td>0.1</td></tr><tr><td>2002-12-03 07:00:00</td><td>0.2</td></tr><tr><td>2002-12-04 07:00:00</td><td>0.1</td></tr><tr><td>2002-12-05 07:00:00</td><td>1.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2018-12-27 07:00:00</td><td>0.0</td></tr><tr><td>2018-12-28 07:00:00</td><td>1.0</td></tr><tr><td>2018-12-29 07:00:00</td><td>10.5</td></tr><tr><td>2018-12-30 07:00:00</td><td>4.7</td></tr><tr><td>2018-12-31 07:00:00</td><td>1.7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_875, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2002-12-01 07:00:00 ┆ 3.0     │\n",
       "│ 2002-12-02 07:00:00 ┆ 0.1     │\n",
       "│ 2002-12-03 07:00:00 ┆ 0.2     │\n",
       "│ 2002-12-04 07:00:00 ┆ 0.1     │\n",
       "│ 2002-12-05 07:00:00 ┆ 1.0     │\n",
       "│ …                   ┆ …       │\n",
       "│ 2018-12-27 07:00:00 ┆ 0.0     │\n",
       "│ 2018-12-28 07:00:00 ┆ 1.0     │\n",
       "│ 2018-12-29 07:00:00 ┆ 10.5    │\n",
       "│ 2018-12-30 07:00:00 ┆ 4.7     │\n",
       "│ 2018-12-31 07:00:00 ┆ 1.7     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpcc_id_to_use = 'DE_06303'\n",
    "gpcc_id_name = gpcc_id_to_use.split('DE_')[-1].lstrip('0') # like 6303\n",
    "example_dat_path = existing_gpcc_daily_paths[gpcc_id_to_use][0]\n",
    "f = zipfile.ZipFile(example_dat_path).open(f\"tw_{gpcc_id_name}.dat\")\n",
    "example_gpcc = pl.from_pandas(pd.read_csv(f, skiprows=1, header=None, sep=r'\\s+'))\n",
    "\n",
    "## drop unnecesary columns\n",
    "example_gpcc = example_gpcc.drop([str(i) for i in range(4, 16)])\n",
    "\n",
    "## make datetime column (apparently it's 7am-7pm)\n",
    "example_gpcc = example_gpcc.with_columns(\n",
    "    pl.datetime(pl.col(\"2\"), pl.col(\"1\"), pl.col(\"0\"), 7).alias(\"time\")\n",
    ").drop([\"0\", \"1\", \"2\"])\n",
    "\n",
    "## rename and reorder\n",
    "example_gpcc = example_gpcc.rename({\"3\": rain_col})\n",
    "example_gpcc = example_gpcc.select(['time', rain_col]) ## Reorder (to look nice)\n",
    "\n",
    "example_gpcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_825, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 07:00:00</td><td>0.2</td></tr><tr><td>2006-01-02 07:00:00</td><td>0.0</td></tr><tr><td>2006-01-03 07:00:00</td><td>0.0</td></tr><tr><td>2006-01-04 07:00:00</td><td>0.0</td></tr><tr><td>2006-01-05 07:00:00</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2010-12-26 07:00:00</td><td>0.2</td></tr><tr><td>2010-12-27 07:00:00</td><td>0.0</td></tr><tr><td>2010-12-28 07:00:00</td><td>0.0</td></tr><tr><td>2010-12-29 07:00:00</td><td>0.0</td></tr><tr><td>2010-12-30 07:00:00</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_825, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2006-01-01 07:00:00 ┆ 0.2     │\n",
       "│ 2006-01-02 07:00:00 ┆ 0.0     │\n",
       "│ 2006-01-03 07:00:00 ┆ 0.0     │\n",
       "│ 2006-01-04 07:00:00 ┆ 0.0     │\n",
       "│ 2006-01-05 07:00:00 ┆ 0.0     │\n",
       "│ …                   ┆ …       │\n",
       "│ 2010-12-26 07:00:00 ┆ 0.2     │\n",
       "│ 2010-12-27 07:00:00 ┆ 0.0     │\n",
       "│ 2010-12-28 07:00:00 ┆ 0.0     │\n",
       "│ 2010-12-29 07:00:00 ┆ 0.0     │\n",
       "│ 2010-12-30 07:00:00 ┆ 0.0     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## resample into daily (also round to 1 decimal place) TODO: check offset='7h' part\n",
    "target_gauge_daily = target_gauge.group_by_dynamic(\"time\", every='1d', offset='7h')\\\n",
    "    .agg([\n",
    "                    pl.len().alias(\"n_hours\"),\n",
    "                    pl.col(rain_col).mean().round(1).alias(rain_col),\n",
    "            ])\\\n",
    "    .filter(pl.col(\"n_hours\") == 24).drop(\"n_hours\")  # Ensure at least 24 data points\n",
    "target_gauge_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d71e3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th><th>rain_mm_GPCC_6303</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 07:00:00</td><td>0.2</td><td>0.2</td></tr><tr><td>2006-01-02 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-03 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-04 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-05 07:00:00</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────┬─────────┬───────────────────┐\n",
       "│ time                ┆ rain_mm ┆ rain_mm_GPCC_6303 │\n",
       "│ ---                 ┆ ---     ┆ ---               │\n",
       "│ datetime[μs]        ┆ f64     ┆ f64               │\n",
       "╞═════════════════════╪═════════╪═══════════════════╡\n",
       "│ 2006-01-01 07:00:00 ┆ 0.2     ┆ 0.2               │\n",
       "│ 2006-01-02 07:00:00 ┆ 0.0     ┆ 0.0               │\n",
       "│ 2006-01-03 07:00:00 ┆ 0.0     ┆ 0.0               │\n",
       "│ 2006-01-04 07:00:00 ┆ 0.0     ┆ 0.0               │\n",
       "│ 2006-01-05 07:00:00 ┆ 0.0     ┆ 0.0               │\n",
       "└─────────────────────┴─────────┴───────────────────┘"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_gauges_gpcc = target_gauge_daily.join(example_gpcc, on='time', suffix=f'_GPCC_{gpcc_id_name}')\n",
    "joined_gauges_gpcc = joined_gauges_gpcc.drop_nans()\n",
    "joined_gauges_gpcc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa02e4b",
   "metadata": {},
   "source": [
    "## Step 8 Compute factor, affinity index and correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bcde4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.1 0.1\n"
     ]
    }
   ],
   "source": [
    "a = np.around(joined_gauges_gpcc.filter(pl.col(rain_col) >= 0.1).min()[rain_col], 1)[0]\n",
    "b = np.around(joined_gauges_gpcc.filter(pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") >= 0.1).min()[f\"{rain_col}_GPCC_{gpcc_id_name}\"], 1)[0]\n",
    "p = max(a, b, 0.1)\n",
    "print(a, b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad3a15da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_760, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th><th>rain_mm_GPCC_6303</th><th>factor</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 07:00:00</td><td>0.2</td><td>0.2</td><td>1.0</td></tr><tr><td>2006-01-02 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>2006-01-03 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>2006-01-04 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>2006-01-05 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2010-12-26 07:00:00</td><td>0.2</td><td>3.0</td><td>0.066667</td></tr><tr><td>2010-12-27 07:00:00</td><td>0.0</td><td>0.4</td><td>NaN</td></tr><tr><td>2010-12-28 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>2010-12-29 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr><tr><td>2010-12-30 07:00:00</td><td>0.0</td><td>0.0</td><td>NaN</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_760, 4)\n",
       "┌─────────────────────┬─────────┬───────────────────┬──────────┐\n",
       "│ time                ┆ rain_mm ┆ rain_mm_GPCC_6303 ┆ factor   │\n",
       "│ ---                 ┆ ---     ┆ ---               ┆ ---      │\n",
       "│ datetime[μs]        ┆ f64     ┆ f64               ┆ f64      │\n",
       "╞═════════════════════╪═════════╪═══════════════════╪══════════╡\n",
       "│ 2006-01-01 07:00:00 ┆ 0.2     ┆ 0.2               ┆ 1.0      │\n",
       "│ 2006-01-02 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ 2006-01-03 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ 2006-01-04 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ 2006-01-05 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ …                   ┆ …       ┆ …                 ┆ …        │\n",
       "│ 2010-12-26 07:00:00 ┆ 0.2     ┆ 3.0               ┆ 0.066667 │\n",
       "│ 2010-12-27 07:00:00 ┆ 0.0     ┆ 0.4               ┆ NaN      │\n",
       "│ 2010-12-28 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ 2010-12-29 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "│ 2010-12-30 07:00:00 ┆ 0.0     ┆ 0.0               ┆ NaN      │\n",
       "└─────────────────────┴─────────┴───────────────────┴──────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_gauges_gpcc_duplicates = joined_gauges_gpcc.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(rain_col) > p) &\n",
    "        (pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") > p)\n",
    "    ).then(1)\n",
    "    .when(\n",
    "        (pl.col(rain_col) == p) &\n",
    "        (pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") == p),\n",
    "    ).then(1)\n",
    "    .when(\n",
    "        (pl.col(rain_col) == p) &\n",
    "        (pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") > p),\n",
    "    ).then(0)\n",
    "    .when(\n",
    "        (pl.col(rain_col) > p) &\n",
    "        (pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") == p)\n",
    "    ).then(0)\n",
    "    .otherwise(np.nan)\n",
    "    .alias(\"duplicate\")\n",
    ")\n",
    "\n",
    "joined_gauges_gpcc = joined_gauges_gpcc.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(rain_col) > 0) & (pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\") > 0)\n",
    "    ).then(pl.col(rain_col) / pl.col(f\"{rain_col}_GPCC_{gpcc_id_name}\"))\n",
    "    .otherwise(np.nan)\n",
    "    .alias(\"factor\")\n",
    ")\n",
    "joined_gauges_gpcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b238361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: 164, match:541\n",
      "affinity: 0.7673758865248227, p_corr: 0.009778374017001294, f_mean: 0.21056017953340903\n"
     ]
    }
   ],
   "source": [
    "match = joined_gauges_gpcc_duplicates['duplicate'].value_counts().filter(pl.col('duplicate') == 1)['count'].item()\n",
    "diff = joined_gauges_gpcc_duplicates['duplicate'].value_counts().filter(pl.col('duplicate') == 0)['count'].item()\n",
    "perc = match / (match + diff)\n",
    "p_corr = np.corrcoef(joined_gauges_gpcc[rain_col], joined_gauges_gpcc[f\"{rain_col}_GPCC_{gpcc_id_name}\"])[0, 1]\n",
    "f_mean = joined_gauges_gpcc['factor'].drop_nans().mean()\n",
    "print(f\"diff: {diff}, match:{match}\")\n",
    "print(f\"affinity: {perc}, p_corr: {p_corr}, f_mean: {f_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a201cf",
   "metadata": {},
   "source": [
    "## Part 9 Compare target with neighbour (hourly and daily)\n",
    "- For hourly data, the data is first converted to daily to do comparison\n",
    "\n",
    "_Output:_ df with long list of neighbour columns and flags\n",
    "\n",
    "Works by computing differences from target and each of its neighbours then collates all those differences and associated difference flags into a single flag/column that describes how similar target is from neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2ced7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc_id_to_use = 'DE_00310'\n",
    "gpcc_id_name = gpcc_id_to_use.split('DE_')[-1].lstrip('0') # like 6303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fead6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th><th>rain_mm_GPCC_310</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 07:00:00</td><td>0.2</td><td>0.2</td></tr><tr><td>2006-01-02 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-03 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-04 07:00:00</td><td>0.0</td><td>0.0</td></tr><tr><td>2006-01-05 07:00:00</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────┬─────────┬──────────────────┐\n",
       "│ time                ┆ rain_mm ┆ rain_mm_GPCC_310 │\n",
       "│ ---                 ┆ ---     ┆ ---              │\n",
       "│ datetime[μs]        ┆ f64     ┆ f64              │\n",
       "╞═════════════════════╪═════════╪══════════════════╡\n",
       "│ 2006-01-01 07:00:00 ┆ 0.2     ┆ 0.2              │\n",
       "│ 2006-01-02 07:00:00 ┆ 0.0     ┆ 0.0              │\n",
       "│ 2006-01-03 07:00:00 ┆ 0.0     ┆ 0.0              │\n",
       "│ 2006-01-04 07:00:00 ┆ 0.0     ┆ 0.0              │\n",
       "│ 2006-01-05 07:00:00 ┆ 0.0     ┆ 0.0              │\n",
       "└─────────────────────┴─────────┴──────────────────┘"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_gauges_gpcc = target_gauge_daily.join(example_gpcc, on='time', suffix=f'_GPCC_{gpcc_id_name}')\n",
    "joined_gauges_gpcc = joined_gauges_gpcc.drop_nans()\n",
    "joined_gauges_gpcc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac9d9c",
   "metadata": {},
   "source": [
    "## Part 9.1 Wet neighbours\n",
    "- This is normalised difference\n",
    "TODO: Problem that there is not enough data which is wetter in the target than in the GPCC neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d887356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4625ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_gauges_gpcc_normalised_diff = joined_gauges_gpcc.with_columns(\n",
    "    # get normalised difference between target and neighbour\n",
    "    rain_mm_normalised_diff = normalise_data(pl.col(f'{rain_col}')) - normalise_data(pl.col(f'{rain_col}_GPCC_{gpcc_id_name}'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf88685",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_gauges_gpcc_normalised_diff_filtered = joined_gauges_gpcc_normalised_diff.filter(\n",
    "    (pl.col(f'{rain_col}') >= 1.0) &\n",
    "    (pl.col(f'{rain_col}').is_finite()) &\n",
    "    (pl.col(f'{rain_col}_GPCC_{gpcc_id_name}').is_finite()) &\n",
    "    (pl.col(f'{rain_col}_normalised_diff') > 0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0611abff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th><th>rain_mm_GPCC_310</th><th>rain_mm_normalised_diff</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2006-12-23 07:00:00</td><td>112.5</td><td>0.0</td><td>0.352886</td></tr><tr><td>2006-12-24 07:00:00</td><td>318.8</td><td>0.0</td><td>1.0</td></tr><tr><td>2007-03-16 07:00:00</td><td>3.1</td><td>0.1</td><td>0.008626</td></tr><tr><td>2007-04-22 07:00:00</td><td>208.1</td><td>0.0</td><td>0.65276</td></tr><tr><td>2008-06-29 07:00:00</td><td>4.2</td><td>0.0</td><td>0.013174</td></tr><tr><td>2008-07-29 07:00:00</td><td>4.3</td><td>0.5</td><td>0.008</td></tr><tr><td>2009-08-30 07:00:00</td><td>1.7</td><td>0.0</td><td>0.005332</td></tr><tr><td>2009-11-06 07:00:00</td><td>9.8</td><td>1.2</td><td>0.017568</td></tr><tr><td>2010-08-09 07:00:00</td><td>1.3</td><td>0.0</td><td>0.004078</td></tr><tr><td>2010-08-12 07:00:00</td><td>1.7</td><td>0.0</td><td>0.005332</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌─────────────────────┬─────────┬──────────────────┬─────────────────────────┐\n",
       "│ time                ┆ rain_mm ┆ rain_mm_GPCC_310 ┆ rain_mm_normalised_diff │\n",
       "│ ---                 ┆ ---     ┆ ---              ┆ ---                     │\n",
       "│ datetime[μs]        ┆ f64     ┆ f64              ┆ f64                     │\n",
       "╞═════════════════════╪═════════╪══════════════════╪═════════════════════════╡\n",
       "│ 2006-12-23 07:00:00 ┆ 112.5   ┆ 0.0              ┆ 0.352886                │\n",
       "│ 2006-12-24 07:00:00 ┆ 318.8   ┆ 0.0              ┆ 1.0                     │\n",
       "│ 2007-03-16 07:00:00 ┆ 3.1     ┆ 0.1              ┆ 0.008626                │\n",
       "│ 2007-04-22 07:00:00 ┆ 208.1   ┆ 0.0              ┆ 0.65276                 │\n",
       "│ 2008-06-29 07:00:00 ┆ 4.2     ┆ 0.0              ┆ 0.013174                │\n",
       "│ 2008-07-29 07:00:00 ┆ 4.3     ┆ 0.5              ┆ 0.008                   │\n",
       "│ 2009-08-30 07:00:00 ┆ 1.7     ┆ 0.0              ┆ 0.005332                │\n",
       "│ 2009-11-06 07:00:00 ┆ 9.8     ┆ 1.2              ┆ 0.017568                │\n",
       "│ 2010-08-09 07:00:00 ┆ 1.3     ┆ 0.0              ┆ 0.004078                │\n",
       "│ 2010-08-12 07:00:00 ┆ 1.7     ┆ 0.0              ┆ 0.005332                │\n",
       "└─────────────────────┴─────────┴──────────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_gauges_gpcc_normalised_diff_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "757b30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original methodology needs there to be at least 30 values to fit exponential function\n"
     ]
    }
   ],
   "source": [
    "if not len(joined_gauges_gpcc_normalised_diff_filtered) >= 30:\n",
    "    print('Original methodology needs there to be at least 30 values to fit exponential function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expon_params = scipy.stats.expon.fit(joined_gauges_gpcc_normalised_diff_filtered[f'{rain_col}_normalised_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e1e547b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate thresholds at key percentiles of fitted distribution\n",
    "q95 = scipy.stats.expon.ppf(0.95, expon_params[0], expon_params[1])\n",
    "q99 = scipy.stats.expon.ppf(0.99, expon_params[0], expon_params[1])\n",
    "q999 = scipy.stats.expon.ppf(0.999, expon_params[0], expon_params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ee998d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6113065102667703),\n",
       " np.float64(0.937536237060823),\n",
       " np.float64(1.4042654597317614))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q95, q99, q999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ce769f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign flags\n",
    "joined_gauges_gpcc_normalised_diff = joined_gauges_gpcc_normalised_diff.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(rain_col) >= 1.0) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') <= q95)\n",
    "    ).then(0)\n",
    "    .when(\n",
    "        (pl.col(rain_col) >= 1.0) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') > q95) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') <= q99),\n",
    "    ).then(1)\n",
    "    .when(\n",
    "        (pl.col(rain_col) >= 1.0) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') > q99) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') <= q999),\n",
    "    ).then(2)\n",
    "    .when(\n",
    "        (pl.col(rain_col) >= 1.0) &\n",
    "        (pl.col(f'{rain_col}_normalised_diff') > q95)\n",
    "    ).then(3)\n",
    "    .otherwise(0)\n",
    "    .alias(\"temp_flags\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "12c34376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>temp_flags</th><th>count</th></tr><tr><td>i32</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>0</td><td>1758</td></tr><tr><td>2</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────┬───────┐\n",
       "│ temp_flags ┆ count │\n",
       "│ ---        ┆ ---   │\n",
       "│ i32        ┆ u32   │\n",
       "╞════════════╪═══════╡\n",
       "│ 1          ┆ 1     │\n",
       "│ 0          ┆ 1758  │\n",
       "│ 2          ┆ 1     │\n",
       "└────────────┴───────┘"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_gauges_gpcc_normalised_diff['temp_flags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776dea03",
   "metadata": {},
   "source": [
    "## Part 9.2 Dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da725f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  elif high_or_dry == \"dry\":\n",
    "\n",
    "#                 # Assign flags\n",
    "#                 # - consider only whether dry 15-day periods at the target are\n",
    "#                 # corroborated as dry by neighbours\n",
    "#                 # - check based on whether 0, 1, 2 or >= 3 wet days are recorded at the\n",
    "#                 # neighbour when the target is dry over the 15-day period\n",
    "#                 # - dry flag works on the basis of fraction of dry days within 15-day\n",
    "#                 # moving window, so 1 = all dry, 0 = all wet\n",
    "#                 # -- truncating these fractions to 2 dp below and manipulating equalities\n",
    "#                 # to work with these fractions, but could work in days not fractions if\n",
    "#                 # change the convertToDrySpell function\n",
    "#                 # - in dry day fraction calcs a threshold of 0 mm is currently used to\n",
    "#                 # identify days as wet (i.e. any rainfall)\n",
    "#                 frac_drydays = {}\n",
    "#                 for d in range(1, 3 + 1):\n",
    "#                     frac_drydays[d] = np.trunc((1.0 - (float(d) / 15.0)) * 10 ** 2) / (10 ** 2)\n",
    "#                 conditions = [\n",
    "#                     (df['ts1'] == 1.0) & (df['ts2'] == 1.0),\n",
    "#                     (df['ts1'] == 1.0) & (df['ts2'] < 1.0) & (df['ts2'] >= frac_drydays[1]),\n",
    "#                     (df['ts1'] == 1.0) & (df['ts2'] < frac_drydays[1]) & (df['ts2'] >= frac_drydays[2]),\n",
    "#                     (df['ts1'] == 1.0) & (df['ts2'] < frac_drydays[2])]  # & (df['ts2'] >= frac_drydays[3])\n",
    "#                 choices = [0, 1, 2, 3]\n",
    "\n",
    "#                 # *** dp 27/11/2019 *** - commented out line below so changed to default=0\n",
    "#                 # normalized_df['temp_flags'] = np.select(conditions, choices, default=np.nan)\n",
    "#                 # normalized_df['temp_flags'] = np.select(conditions, choices, default=0)\n",
    "#                 df['temp_flags'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "#                 # tempFlags = normalized_df['temp_flags']\n",
    "#                 temp_flags = df['temp_flags']\n",
    "#                 return temp_flags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a80cbc",
   "metadata": {},
   "source": [
    "## Part 10 Compare target with neighbour (monthly) \n",
    "- Works differently from hourly and daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717207a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60febab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8d0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301fb685",
   "metadata": {},
   "source": [
    "# QC16 - Daily neighbours (wet)\n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- Many, although mainly this implementation opens the neighbour wet and dry functions to parameter tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05ca0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resample data into daily (NOTE: OG method makes sure this is 7am-7pm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2adc501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 'DE_06303'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daa4cc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (43_824, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 00:00:00</td><td>0.9</td></tr><tr><td>2006-01-01 01:00:00</td><td>0.3</td></tr><tr><td>2006-01-01 02:00:00</td><td>0.3</td></tr><tr><td>2006-01-01 03:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 04:00:00</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2010-12-31 19:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 20:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 21:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 22:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 23:00:00</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (43_824, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2006-01-01 00:00:00 ┆ 0.9     │\n",
       "│ 2006-01-01 01:00:00 ┆ 0.3     │\n",
       "│ 2006-01-01 02:00:00 ┆ 0.3     │\n",
       "│ 2006-01-01 03:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 04:00:00 ┆ 0.0     │\n",
       "│ …                   ┆ …       │\n",
       "│ 2010-12-31 19:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 20:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 21:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 22:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 23:00:00 ┆ 0.0     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651a9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6010346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01e885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb4369f0-5c04-47d7-8f6d-9b6761b054e9",
   "metadata": {},
   "source": [
    "# QC17 - Hourly neighbours (wet) \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f7483e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 'DE_06264'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b7da073",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbouring_gauge = get_neighbour_gauge_data(neighbour_gauge_id=example_id, time_multiplying_factor=MULTIPLYING_FACTORS['hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1be7dab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (43_824, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>rain_mm</th></tr><tr><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>2006-01-01 00:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 01:00:00</td><td>0.1</td></tr><tr><td>2006-01-01 02:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 03:00:00</td><td>0.0</td></tr><tr><td>2006-01-01 04:00:00</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2010-12-31 19:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 20:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 21:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 22:00:00</td><td>0.0</td></tr><tr><td>2010-12-31 23:00:00</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (43_824, 2)\n",
       "┌─────────────────────┬─────────┐\n",
       "│ time                ┆ rain_mm │\n",
       "│ ---                 ┆ ---     │\n",
       "│ datetime[μs]        ┆ f64     │\n",
       "╞═════════════════════╪═════════╡\n",
       "│ 2006-01-01 00:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 01:00:00 ┆ 0.1     │\n",
       "│ 2006-01-01 02:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 03:00:00 ┆ 0.0     │\n",
       "│ 2006-01-01 04:00:00 ┆ 0.0     │\n",
       "│ …                   ┆ …       │\n",
       "│ 2010-12-31 19:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 20:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 21:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 22:00:00 ┆ 0.0     │\n",
       "│ 2010-12-31 23:00:00 ┆ 0.0     │\n",
       "└─────────────────────┴─────────┘"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbouring_gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE_06264\n",
      "0.1 0.1 0.1\n",
      "diff: 174, match:379\n",
      "perc: 0.6853526220614828, p_corr: 0.0024745444582926776, f_mean: 2.8794833506858817\n",
      "###############\n",
      "DE_01300\n",
      "0.1 0.1 0.1\n",
      "diff: 94, match:508\n",
      "perc: 0.8438538205980066, p_corr: 0.001977647232117444, f_mean: 2.1665778878233475\n",
      "###############\n",
      "DE_06303\n",
      "0.1 0.1 0.1\n",
      "diff: 140, match:487\n",
      "perc: 0.7767145135566188, p_corr: 0.004315394781542508, f_mean: 2.36290034326275\n",
      "###############\n",
      "DE_02718\n",
      "0.1 0.1 0.1\n",
      "diff: 178, match:366\n",
      "perc: 0.6727941176470589, p_corr: 0.003670924337190943, f_mean: 3.0951548717106143\n",
      "###############\n",
      "DE_04488\n",
      "0.1 0.1 0.1\n",
      "diff: 98, match:439\n",
      "perc: 0.8175046554934823, p_corr: 0.003425391979961906, f_mean: 2.139130209744735\n",
      "###############\n",
      "DE_00310\n",
      "0.1 0.1 0.1\n",
      "diff: 124, match:455\n",
      "perc: 0.7858376511226253, p_corr: 0.004957314033425343, f_mean: 2.3426827802109726\n",
      "###############\n",
      "DE_03215\n",
      "0.1 0.1 0.1\n",
      "diff: 99, match:268\n",
      "perc: 0.7302452316076294, p_corr: 0.04958692601219599, f_mean: 2.738944066476524\n",
      "###############\n",
      "DE_00390\n",
      "0.1 0.1 0.1\n",
      "diff: 136, match:431\n",
      "perc: 0.7601410934744268, p_corr: 0.002783363659116628, f_mean: 2.302766863828049\n",
      "###############\n",
      "DE_04313\n",
      "0.1 0.1 0.1\n",
      "diff: 176, match:381\n",
      "perc: 0.6840215439856373, p_corr: -0.0001193839411150456, f_mean: 3.0275432253569745\n",
      "###############\n"
     ]
    }
   ],
   "source": [
    "for n_id in all_neighbour_ids_paths.keys():\n",
    "    print(n_id)\n",
    "    one_neighbouring_gauge = get_neighbour_gauge_data(neighbour_gauge_id=n_id, time_multiplying_factor=MULTIPLYING_FACTORS['hourly'])\n",
    "    joined_gauges = target_gauge.join(one_neighbouring_gauge, on='time', suffix=f'_{n_id}')\n",
    "    joined_gauges = joined_gauges.drop_nans()\n",
    "\n",
    "    ## resample into daily (also round to 1 decimal place) TODO: remove offset part\n",
    "    joined_gauges = joined_gauges.group_by_dynamic(\"time\", every='1d', offset='7h')\\\n",
    "        .agg([\n",
    "                     pl.len().alias(\"n_hours\"),\n",
    "                     pl.col(rain_col).mean().round(1).alias(rain_col),\n",
    "                     pl.col(f'{rain_col}_{n_id}').mean().round(1).alias(f'{rain_col}_{n_id}')\n",
    "             ])\\\n",
    "        .filter(pl.col(\"n_hours\") == 24).drop(\"n_hours\")  # Ensure at least 24 data points\n",
    "\n",
    "    ## NOTE: is this necessary? Why not just read resolution of each data?\n",
    "    a = np.around(joined_gauges.filter(pl.col(rain_col) >= 0.1).min()[rain_col], 1)[0]\n",
    "    b = np.around(joined_gauges.filter(pl.col(f\"{rain_col}_{n_id}\") >= 0.1).min()[f\"{rain_col}_{n_id}\"], 1)[0]\n",
    "    p = max(a, b, 0.1)\n",
    "    print(a, b, p)\n",
    "\n",
    "    ## TODO: rename all variables\n",
    "    joined_gauges_duplicates = joined_gauges.with_columns(\n",
    "        pl.when(\n",
    "            (pl.col(rain_col) > p) &\n",
    "            (pl.col(f\"{rain_col}_{n_id}\") > p)\n",
    "        ).then(1)\n",
    "        .when(\n",
    "            (pl.col(rain_col) == p) &\n",
    "            (pl.col(f\"{rain_col}_{n_id}\") == p),\n",
    "        ).then(1)\n",
    "        .when(\n",
    "            (pl.col(rain_col) == p) &\n",
    "            (pl.col(f\"{rain_col}_{n_id}\") > p),\n",
    "        ).then(0)\n",
    "        .when(\n",
    "            (pl.col(rain_col) > p) &\n",
    "            (pl.col(f\"{rain_col}_{n_id}\") == p)\n",
    "        ).then(0)\n",
    "        .otherwise(np.nan)\n",
    "        .alias(\"duplicate\")\n",
    "    )\n",
    "\n",
    "    joined_gauges = joined_gauges.with_columns(\n",
    "        pl.when(\n",
    "            (pl.col(rain_col) > 0) & (pl.col(f\"{rain_col}_{n_id}\") > 0)\n",
    "        ).then(pl.col(rain_col) / pl.col(f\"{rain_col}_{n_id}\"))\n",
    "        .otherwise(np.nan)\n",
    "        .alias(\"factor\")\n",
    "    )\n",
    "\n",
    "    match = joined_gauges_duplicates['duplicate'].value_counts().filter(pl.col('duplicate') == 1)['count'].item()\n",
    "    diff = joined_gauges_duplicates['duplicate'].value_counts().filter(pl.col('duplicate') == 0)['count'].item()\n",
    "    affinity = match / (match + diff)\n",
    "    p_corr = np.corrcoef(joined_gauges[rain_col], joined_gauges[f\"{rain_col}_{n_id}\"])[0, 1]\n",
    "    f_mean = joined_gauges['factor'].drop_nans().mean()\n",
    "    print(f\"diff: {diff}, match:{match}\")\n",
    "    print(f\"affinity: {affinity}, p_corr: {p_corr}, f_mean: {f_mean}\")\n",
    "\n",
    "    print(\"#\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55b800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75c95086-cd30-4232-a598-98c6ba4744d8",
   "metadata": {},
   "source": [
    "# QC18 - Daily neighbours (dry) \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748457c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf6965-3206-473e-98fb-9d666b84e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d73b55d-70ca-4a7f-9ccb-eb7c8220b834",
   "metadata": {},
   "source": [
    "# QC19 - Hourly neighbours (dry) \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d36f5-06a5-41cc-a586-28cbe36b2ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26abff0-392f-4598-ba76-3d054608521b",
   "metadata": {},
   "source": [
    "# QC20 - Monthly neighbours\n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c302184-8c8f-4683-a03b-ce8660f5ed7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35a03907-142a-4c08-8ab3-ae0fe5f3f493",
   "metadata": {},
   "source": [
    "# QC21 - Timing offset \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15a579-446c-43f1-9570-11ab92cfbe82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f372ec0e-7d3b-44c8-a052-806e66454834",
   "metadata": {},
   "source": [
    "# QC22 - Pre-QC Affinity  \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1294be1-19a5-42c4-8c89-5f5112326ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b52dfb5b-44d6-481b-b3ac-8c562df044d4",
   "metadata": {},
   "source": [
    "# QC23 - Pre-QC Pearson\n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abacf73-41a8-463b-97e4-c87f3ec7b63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad5d0b8-a686-435a-b35d-8685e97ec8fd",
   "metadata": {},
   "source": [
    "# QC24 - Daily factor  \n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce16043-48bc-411c-9b0a-be611f95d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f63fafe7-f52e-4dc7-beec-380828762245",
   "metadata": {},
   "source": [
    "# QC25 - Monthly factor\n",
    "[Back to Index](#Table-of-contents)\n",
    "\n",
    "#### Differences from `intense-qc`: \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea02d33-4923-41e0-8453-2ad9c13dae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainfallqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
